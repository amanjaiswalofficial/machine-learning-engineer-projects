{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06: Creating FAISS Indices from the Fine-Tuned Model\n",
    "\n",
    "**Objective:** To generate a new set of vector embeddings and FAISS indices using our specialized, fine-tuned sentence transformer model.\n",
    "\n",
    "**Why is this necessary?** Our fine-tuned model now represents text differently than the original, generic model. The vector space has been altered to be more specific to travel reviews. Therefore, our old FAISS indices, which were built with the old model's vectors, are now incompatible. We must re-generate all embeddings and indices to match the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Data and the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the fine-tuned model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# --- Load the FINE-TUNED model ---\n",
    "# This is the most important change. We are loading our specialized model.\n",
    "print(\"Loading the fine-tuned model...\")\n",
    "model = SentenceTransformer('./fine_tuned_model')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# --- Load the raw data ---\n",
    "PATH = \"/Users/amanjaiswal/Work/hop_v3/backend/combined_results.csv\"\n",
    "df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pre-process and Feature Engineering (Same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete.\n"
     ]
    }
   ],
   "source": [
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return []\n",
    "\n",
    "df['detailed_reviews'] = df['detailed_reviews'].apply(safe_literal_eval)\n",
    "df_reviews_exploded = df[['place_id', 'detailed_reviews']].explode('detailed_reviews')\n",
    "df_reviews_exploded_filtered = df_reviews_exploded[df_reviews_exploded['detailed_reviews'].apply(lambda x: isinstance(x, dict) and bool(x))]\n",
    "df_reviews = pd.json_normalize(df_reviews_exploded_filtered['detailed_reviews'])\n",
    "df_reviews['place_id'] = df_reviews_exploded_filtered['place_id'].values\n",
    "place_features = ['place_id', 'name', 'main_category', 'rating', 'address', 'reviews']\n",
    "df_places = df[place_features]\n",
    "flat_df = df_reviews.merge(df_places, on='place_id', how='left', suffixes=('_review', '_place'))\n",
    "\n",
    "filtered_df = flat_df[flat_df['rating_review'] >= 3]\n",
    "vibe_df = filtered_df.groupby(\n",
    "    ['place_id', 'name_place', 'main_category', 'rating_place', 'address', 'reviews']\n",
    ")['review_text'].apply(lambda texts: ' '.join([str(t) for t in texts if pd.notna(t)])).reset_index()\n",
    "vibe_df.rename(columns={\n",
    "    'name_place': 'place_name',\n",
    "    'rating_place': 'avg_place_rating',\n",
    "    'review_text': 'combined_reviews'\n",
    "}, inplace=True)\n",
    "\n",
    "def extract_city_from_query(query):\n",
    "    if pd.isna(query):\n",
    "        return \"unknown\"\n",
    "    query = query.lower().strip()\n",
    "    match = re.search(r'in\\s+([a-z\\s]+)$', query)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"unknown\"\n",
    "\n",
    "df['city'] = df['query'].apply(extract_city_from_query)\n",
    "vibe_df = vibe_df.merge(df[['place_id', 'city']].drop_duplicates(), on='place_id', how='left')\n",
    "\n",
    "print(\"Data processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate New Embeddings and Build New FAISS Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dfca8abcbf45468fbc377b96d418eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding generation complete.\n",
      "Building new FAISS indices...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394696d5d97343ebbaef124d239df375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building city indices:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index building complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Generate new embeddings with the fine-tuned model ---\n",
    "print(\"Generating new embeddings...\")\n",
    "vibe_df['embedding'] = vibe_df['combined_reviews'].progress_apply(lambda x: model.encode(x) if isinstance(x, str) else model.encode(\"\"))\n",
    "print(\"Embedding generation complete.\")\n",
    "\n",
    "# --- Build new FAISS index for each city ---\n",
    "print(\"Building new FAISS indices...\")\n",
    "city_indices_finetuned = {}\n",
    "for city, group in tqdm(vibe_df.groupby('city'), desc=\"Building city indices\"):\n",
    "    if city == 'unknown' or group.empty:\n",
    "        continue\n",
    "    \n",
    "    embeddings = np.vstack(group['embedding'].values).astype('float32')\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    \n",
    "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    city_indices_finetuned[city] = {\n",
    "        'index': index,\n",
    "        'df': group.reset_index(drop=True)\n",
    "    }\n",
    "\n",
    "print(\"Index building complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save the New Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New fine-tuned indices saved to: city_faiss_indices_finetuned.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Save the new indices to a new file ---\n",
    "output_path = \"city_faiss_indices_finetuned.pkl\"\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(city_indices_finetuned, f)\n",
    "\n",
    "print(f\"New fine-tuned indices saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
